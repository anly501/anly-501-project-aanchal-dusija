
<HTML>
	<head>
		<link rel="stylesheet" href="../styles.css">
	  </head>

	<body>
	    <a href="https://analytics.georgetown.edu/"><img src="https://ngpardeshi.georgetown.domains/ANLY 501 IMAGES/DSA.jpg" style="width:600px;height:200px;" /> 
			<img src="https://ngpardeshi.georgetown.domains/ANLY 501 IMAGES/GU_Background.png" style="width:700px;height:200px;" align="right">
		 </a> 
	<ul class ="header">
		<!-- link back to homepage -->
		<li><a href="../index.html">About me</a></li>
		
		<!-- tab without dropdown  -->
		<li><a href="../pages/introduction.html">Introduction</a></li>
		<li><a href="../pages/DataGathering.html">Data Gathering</a></li>
		<li><a href="https://github.com/anly501/anly-501-project-aanchal-dusija">Data</a></li>
		<li><a href="https://github.com/anly501/anly-501-project-aanchal-dusija">Code</a></li>
		<li><a href="../pages/DataCleaning.html">Data Cleaning</a></li>
		<li><a href="../pages/Exploring Data.html">Exploring Data</a></li>
		<li class="dropdown">
			<a href="javascript:void(0)" class="dropbtn">Naive Bayes</a>
		
			<div class="dropdown-content">
			<a href="../pages/NaiveBayesRPage.html" >Naive Bayes in R</a>
			<a href="../pages/NBinPy_quarto.html" >Naive Bayes in Python</a>
			</div>
		</li>
		<li><a href="../pages/Clustering.html">Clustering</a></li>
		<li><a href="../pages/ARM.html">ARM and Networking</a></li>
		<li><a href="../pages/DT.html">Decision Trees</a></li>
		<!-- <li><a href="../pages/xyz.html">Naive Bayes</a></li> -->
		<li><a href="../pages/SVM.html">SVM</a></li>
		<li><a href="../pages/xyz.html">Conclusions</a></li>
		
	</ul>
	<div class="content">
	<div class="w3-container w3-border city" id="Naive Bayes" >
	<h1><center><b>Naive Bayes</b></center></h1>
	<p><center>This page contains the Naive Bayes code and visualizations done in R for Record data and in Python for Text data. 
	
	<h3><b>What is Naive Bayes</b></h3>
	<p> It is a classification technique based on Bayes Theorem with an assumption of independence among predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. Naive Bayes model is easy to build and particularly useful for very large data sets. Along with simplicity, Naive Bayes is known to outperform even highly sophisticated classification methods. </p>
	<br>			
	<h2><b>Naive Bayes in R</b></h2>
	<p> The naive bayes is created using Macy's dataset in R. It is the same record dataset used for decision trees. The dataset has been webscrapped from the Macy's official website. This dataset has been cleaned and now consists of various features like Rating, Average Price, Stock of each colour, Total Stock, and Price Type.The label column contains the data of whether the item is expensive (average price greater than or equal to $100) or reasonable(average price less than $100).  </p>
	
	<p><center>The snapshot of the dataset and the link to the csv file is attached below.</center></p>
	<center><img alt="NBR.png" height="400px" src="NBR.png" width="700px" /></center>
				<center><a href="NBR.png" target="new">View </a></center>
				<a href="NBR.png" target="new"> </a>
	
				<center><a href="macy_mw.csv">Download csv file</a></center>
	<br>			
	<h3><b>Cleaning and formatting the dataset to the required format</b></h3>
	<!-- <p> The code to create clean and format the datasets can be found  <a href="NBinR.R" target="_blank">here</a> </p> -->
	<p>There are a lot of unwated columns in the dataframe. These columns are dropped from the dataframe, retaining only the necessary columns. There is exploratory data analysis performed to understand the dataset. Checking the balance of the dataset and label is very important before performing decision trees, as unbalanced dataset may lead to over or underfitting. </p>
	
	<!-- <p><center>The snapshot of the label column (income) before and after balancing. </center></p>
	<img alt="income_before_bal.jpeg" height="400px" src="income_before_bal.jpeg" width="600px" />
	
	&emsp;
	&emsp;
	<img alt="balance_label.jpeg" height="400px" src="balance_label.jpeg" width="600px" /> -->
	
	<br>
	<h3><b>Model Building</b></h3>
	<p> The code to build the model can be found <a href="NBinR.R" target="_blank">here</a> </p>
	<p>Before building the model, the dataset is split into training and testing sets. The split ratio is 0.75 of the total data in the training set and 0.25 data in the testing set. The naive bayes model is trained using the training dataset and then the model is tested using labels from the testing dataset </p>
	
	<p><center>The snapshot of the naive bayes are attached below.</center></p>
	<p><center><img alt="NBR5.png" height="500px" src="NBR5.png" width="600px" /></center></p>
	<p><center><img alt="NBR2.png" height="400px" src="NBR2.png" width="300px" /></center></p>
	<p><center>The graph to show the key features from the model is attached below.</center></p>
	<p><center><img alt="NBR1.png" height="400px" src="NBR1.png" width="500px" /</center></p>
	
	<h3><b>Conclusion</b></h3>
	<p>The intention was to perform naive bayes to help predict the Price Type of the product given the different features. The accuracy of the model (83%) is good in predicting the price type group. According to the above graph, the key features to predict the income group are Average Price and Total Stock. It makes sense that the variable Price and Stock have a significant impact on Price Type.  </p>
	
	</div>
	
	
	</div>
	
	
	
	
	
	</HTML>