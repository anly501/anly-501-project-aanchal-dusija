
<HTML>

	<!-- <head>
		<title>Naive Bayes in R</title>
		<link rel="stylesheet" href="styles.css">
	</head>
	
	<body style="background-color:#F6F5F5;"> -->
	
	<style>
	
	.container{
		display: flex;
		flex-direction: column;
	}
	
	ibody{
		margin:0;
		min-height: 100%;
		min-width:100%;
		
	}
	
	
	body {
		font-family: verdana;
		background-color : #F6F5F5 ;
		position : relative
		style: #232435;
	
	}
	
	.navbar{
		top:0;
		position: fixed;
		width : 100%;
		
	}
	
	.topnav {
	  overflow: hidden;
	  background-color: #1F1A40;
	}
	
	.topnav a {
	  float: left;
	  color: #BBD8F2;
	  text-align: center;
	  padding: 12px 14px;
	  text-decoration: none;
	  font-size: 17px;
	}
	
	.topnav a:hover {
	  background-color: #D3E0EA;
	  color: black;
	}
	
	.topnav a.active {
	  background-color: #FFFFFF;
	  color: white;
	}
	
	.headerLogo{
	  top:200px;
	  height:250px;
	  width:200px;
	  line-height:200px;
	
	  overflow:hidden;
	 
	  top:200px; height:900px; width:1450px; line-height:500px
	}
	.center {
	  display: block;
	  margin-left: auto;
	  margin-right: auto;
	  width: 100%;
	}
	
	h1 {text-align: left;}
	p {text-align: justify;
		text-justify: inter-word;
	}
	div {text-align: left;}
	
	.content{
		margin-left:0;
		padding : 2% 25% 2% 25%;
	}
	
	ul {
		list-style-type: none;
		margin: 0;
		padding: 0;
		overflow: hidden;
		background-color: #004d99;
		max-width:1500px;
	}
	
	li {
		float: left;
	} -->
	
	<!-- li a, .dropbtn {
		display: inline-block;
		color: white;
		text-align: center;
		padding: 14px 16px;
		text-decoration: none;
	}
	
	li a:hover, .dropdown:hover .dropbtn {
		background-color: #004d99;
	}
	
	li.dropdown {
		display: inline-block;
	}
	
	.dropdown-content {
		display: none;
		position: absolute;
		background-color: white;
		min-width: 160px;
		
		
	}
	
	.dropdown-content a {
		color: black;
		padding: 12px 16px;
		text-decoration: none;
		display: block;
		text-align: left;
		
	}
	
	
	
	.dropdown:hover .dropdown-content {
		display: block;
		opacity: 1;
	}
	td {
		padding: 5px;
		text-align: left;
		width: 500px;
	}
	
	tr{
	   padding: 0px;
	   text-align: top;
	   background-color:#ffffff
	}
	
	img:hover {
	  opacity: 1;
	}
	
	</style>
	
	<!-- <link rel="stylesheet" href="styles.css"> -->
	<div class ="navbar"></div>
	<ul>
		<!-- link back to homepage -->
		<li><a href="../index.html">About me</a></li>
		
		<!-- tab without dropdown  -->
		<li><a href="../pages/introduction.html">Introduction</a></li>
		<li><a href="../pages/DataGathering.html">Data Gathering</a></li>
		<li><a href="https://github.com/anly501/anly-501-project-aanchal-dusija">Data</a></li>
		<li><a href="https://github.com/anly501/anly-501-project-aanchal-dusija">Code</a></li>
		<li><a href="../pages/DataCleaning.html">Data Cleaning</a></li>
		<li><a href="../pages/Exploring Data.html">Exploring Data</a></li>
		<li class="dropdown">
			<a href="javascript:void(0)" class="dropbtn">Naive Bayes</a>
		
			<div class="dropdown-content">
			<a href="../pages/NaiveBayesRPage.html" >Naive Bayes in R</a>
			<a href="../pages/NaiveBayesPyPage.html" >Naive Bayes in Python</a>
			</div>
		</li>
		<li><a href="../pages/xyz.html">Clustering</a></li>
		<li><a href="../pages/xyz.html">ARM and Networking</a></li>
		<li><a href="../pages/xyz.html">Decision Trees</a></li>
		<!-- <li><a href="../pages/xyz.html">Naive Bayes</a></li> -->
		<li><a href="../pages/xyz.html">SVM</a></li>
		<li><a href="../pages/xyz.html">Conclusions</a></li>
		
	</ul>

	<div class="content">
	<div class="w3-container w3-border city" id="Naive Bayes" >
	<h1><center><b>Naive Bayes</b></center></h1>
	<p><center>This page contains the Naive Bayes code and visualizations done in R for Record data and in Python for Text data. 
	
	<h3><b>What is Naive Bayes</b></h3>
	<p> It is a classification technique based on Bayes Theorem with an assumption of independence among predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. Naive Bayes model is easy to build and particularly useful for very large data sets. Along with simplicity, Naive Bayes is known to outperform even highly sophisticated classification methods. </p>
	<br>			

<h2><b>Naive Bayes in Python</b></h2>
<p> The naive bayes is created using text dataset in Python.The tweets are extracted on the hashtag "fashion trends" and hashtag "ecommerce" . The motive behind collecting this text data was to understand the opinion of people regarding fashion trends and different tweets regarding ecommerce. To get a quick overview of the data, a wordcloud of both the hashtags has been made.</p>
<img alt="NBPY1.png" height="400px" src="NBPY1.png" width="600px" />
<!-- &emsp;
&emsp; -->
<img alt="NBPY2.png" height="400px" src="NBPY2.png" width="600px" />

<h3><b>Cleaning and formatting the dataset to the required format</b></h3>
<p>There are a lot of unwated columns in the dataframe. These columns are dropped from the dataframe, retaining only the necessary columns. The stopwords are removed and the text is tokenized, lemmatized and stemmed. Countvectorizer is applied on the data to convert it to numerical format. Checking the balance of the label is very important before performing decision trees, as unbalanced dataset may lead to over or underfitting.  </p>
<p><center>The snapshot of the dataset and the link to the csv file is attached below.</center></p>
<center><img alt="NBPY3.png" height="400px" src="NBPY3.png" width="700px" /></center>
			<center><a href="NBPY3.png" target="new">View </a></center>
			<a href="NBPY3.png" target="new"> </a>

			<center><a href="Clean_Twitter_data.csv">Download csv file</a></center>
<!-- <center><img alt="dtm_cv_small.jpg" height="400px" src="dtm_cv_small.jpg" width="600px" /></center> -->
			<!-- <center><a href="dtm_cv.jpg" target="new">View </a></center> -->
			<!-- <a href="dtm_cv.jpg" target="new"> </a> -->

			<!-- <center><a href="https://sonalipednekar.georgetown.domains/ANLY501/DTM_CV_DT.csv">Download csv file</a></center> -->

<h3><b>Model Building</b></h3>
<p> The code to build the model can be found <a href="NBinPy" target="_blank">here</a> </p>
<p>Before building the model, the dataset is split into training and testing sets. The split ratio is 0.75 of the total data in the training set and 0.25 data in the testing set. Three different naive bayes models are created. The Naive Bayes models differ due to hypertuning of different parameters. Mainly the alpha values.</p>

<p><b> Naive Bayes Model 1</b></p>
<p>This is the first naive bayes model. In this model, the hyperparameter are alpha = 1. In this model, the accuracy is 98%.</p>
<p><center>The snapshot of the accuracy/heatmap is attached below. </center></p>
<center><img alt="NBPY4.png" height="700px" src="NBPY4.png" width="600px" /></center>

<p><b> Naive Bayes Model 2</b></p>
<p>This is the second naive bayes model. In this model, the hyperparameter are alpha = 3. In this model, the accuracy is 98%.</p>
<p><center>The snapshot of the accuracy/heatmap is attached below. </center></p>
<center><img alt="NBPY5.png" height="700px" src="NBPY5.png" width="600px" /></center>

<p><b> Naive Bayes Model 3</b></p>
<p>This is the third naive bayes model. In this model, the hyperparameter are alpha = 0. In this model, the accuracy is 96%.</p>
<p><center>The snapshot of the accuracy/heatmap is attached below. </center></p>
<center><img alt="NBPY6.png" height="700px" src="NBPY6.png" width="600px" /></center>

<h3><b>Conclusion</b></h3>
<p>The Naive Bayes model classified tweets generated from Twitter into the hashtag class (fashiontrends and ecoomerce) of different tweets. The accuracy of the models are 98% and 96%. The accuracy is good. With the collection of words, the model is able to predict or classify the tweets into particular classes.  </p>

	</div>
	
	
	</div>
	
	
	
	
	
	</HTML>